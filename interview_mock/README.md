# TopCV Job Recommendation & CV Screening System v2.1

H·ªá th·ªëng g·ª£i √Ω c√¥ng vi·ªác v√† ch·∫•m ƒëi·ªÉm CV th√¥ng minh s·ª≠ d·ª•ng **Modern Content-Based Filtering** v·ªõi **Embeddings**, **Cosine Similarity** v√† **AI-powered CV Screening**.

## üöÄ Features

### CV Processing
- **Multi-format Support**: PDF, DOCX, JPG, PNG
- **LLM-powered Extraction**: S·ª≠ d·ª•ng Google Gemini ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin structured
- **Smart Skills Detection**: T·ª± ƒë·ªông nh·∫≠n di·ªán 300+ technical skills
- **Experience Calculation**: T√≠nh to√°n t·ªïng s·ªë nƒÉm kinh nghi·ªám t·ª´ work history

### Modern Recommendation Engine
- **Embedding-based Similarity**: S·ª≠ d·ª•ng Sentence Transformers (all-MiniLM-L6-v2)
- **Cosine Similarity**: T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng semantic ch√≠nh x√°c
- **Multi-field Weighted Scoring**: 
  - Skills Matching (40%): Exact + Semantic matching
  - Experience Matching (30%): Years + Semantic description matching  
  - Semantic Similarity (20%): Full CV vs Job description embeddings
  - Education & Location (10%): Traditional rule-based matching
- **Content-Based Filtering**: Ch·ªâ d·ª±a tr√™n n·ªôi dung CV v√† Job, kh√¥ng c·∫ßn user interaction data

### CV Screening for HR
- **AI-powered Evaluation**: S·ª≠ d·ª•ng Google Gemini ƒë·ªÉ ch·∫•m ƒëi·ªÉm CV
- **PostgreSQL Integration**: L·∫•y job data tr·ª±c ti·∫øp t·ª´ database
- **Pass/Fail/Review Decision**: T·ª± ƒë·ªông ph√¢n lo·∫°i ·ª©ng vi√™n
- **Detailed Analysis**: Matching points, gaps analysis, recommendations
- **Score-based Filtering**: Configurable thresholds cho decision making

### API Features
- **RESTful API**: FastAPI v·ªõi auto-generated docs
- **File Upload**: Upload CV v√† nh·∫≠n recommendations ngay
- **Job Management**: Upload v√† qu·∫£n l√Ω job descriptions
- **Filtering**: L·ªçc theo location, job type, experience level
- **Skills Analysis**: Extract v√† validate skills t·ª´ text
- **Screening API**: HR screening endpoints v·ªõi authentication

## üèóÔ∏è Architecture

```
interview_mock/
‚îú‚îÄ‚îÄ config.py                 # C·∫•u h√¨nh h·ªá th·ªëng
‚îú‚îÄ‚îÄ requirements.txt          # Dependencies (includes sentence-transformers + screening)
‚îú‚îÄ‚îÄ screening_cv.py           # CV screening logic v·ªõi Gemini AI
‚îú‚îÄ‚îÄ screening_api.py          # FastAPI service cho CV screening  
‚îú‚îÄ‚îÄ run_screening_service.py  # Script ƒë·ªÉ ch·∫°y screening service
‚îú‚îÄ‚îÄ core/                     # Core modules
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ skills.py            # Skills management
‚îÇ   ‚îú‚îÄ‚îÄ cv_extractor.py      # CV extraction v·ªõi LLM
‚îÇ   ‚îî‚îÄ‚îÄ recommendation_engine.py # Modern embedding-based engine
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ recommendation_service.py # FastAPI service cho recommendations
‚îî‚îÄ‚îÄ TopCV/Backend/            # Java Spring Boot backend
    ‚îî‚îÄ‚îÄ src/main/java/com/TopCV/
        ‚îú‚îÄ‚îÄ controller/ScreeningController.java
        ‚îú‚îÄ‚îÄ service/ScreeningService.java
        ‚îî‚îÄ‚îÄ client/ScreeningServiceClient.java
```

## üîß Installation

### 1. Clone Repository
```bash
git clone <repository-url>
cd interview_mock/interview_mock
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Configure Environment
```bash
# T·∫°o file .env (optional)
GOOGLE_API_KEY=your_google_api_key_here
DATABASE_URL=postgresql://localhost:5432/topcv
```

### 4. Run Services

#### For Job Recommendations:
```bash
# Development mode
python api/recommendation_service.py

# Production mode
uvicorn api.recommendation_service:app --host 0.0.0.0 --port 8000
```

#### For CV Screening (HR):
```bash
# Easy startup
python run_screening_service.py

# Manual startup
uvicorn screening_api:app --host 0.0.0.0 --port 8000 --reload
```

#### Java Backend (TopCV):
```bash
cd TopCV/Backend
./mvnw spring-boot:run
# Backend available at: http://localhost:8080/TopCV
```

## üìñ API Documentation

**TopCV Unified System** bao g·ªìm:
1. **Job Recommendation** (cho ·ª©ng vi√™n t√¨m vi·ªác)
2. **CV Screening** (cho HR ch·∫•m ƒëi·ªÉm CV)

Sau khi start service, truy c·∫≠p:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Job Recommendation Endpoints

#### CV Processing
```bash
# Upload CV v√† nh·∫≠n recommendations  
POST /cv/upload
# Body: multipart/form-data v·ªõi file

# Ph√¢n t√≠ch CV t·ª´ text
POST /cv/analyze-text  
# Body: {"cv_text": "CV content..."}

# Recommend jobs cho CV text
POST /recommend
# Body: {"cv_text": "...", "top_k": 5, "min_score": 0.3}
```

#### Job Management
```bash
# Upload job description
POST /jobs/upload
# Body: {"job_data": {...}}

# L·∫•y danh s√°ch jobs
GET /jobs?limit=20&skip=0&location=H√† N·ªôi

# Th√™m sample jobs (for testing)
POST /test/add-sample-jobs
```

### CV Screening Endpoints (For HR)

#### CV Analysis
```bash
# Ph√¢n t√≠ch CV ·ª©ng vi√™n cho job c·ª• th·ªÉ (t·ª´ PostgreSQL)
POST /screening/cv-analysis
# Body: multipart/form-data
# - cv_file: PDF/DOCX file
# - job_data: JSON string v·ªõi th√¥ng tin job t·ª´ database

# Response: PASS/FAIL/REVIEW decision v·ªõi ƒëi·ªÉm s·ªë chi ti·∫øt
```

#### Recommendations
```bash
# T·∫°o recommendations v·ªõi filters
POST /recommendations/generate
# Body: {
#   "cv_data": {...},
#   "location_filter": "H√† N·ªôi",
#   "top_k": 10,
#   "min_score": 0.3
# }
```

#### Skills & Statistics
```bash
# L·∫•y danh s√°ch skills h·ªó tr·ª£
GET /skills

# Extract skills t·ª´ text
POST /skills/extract

# Th·ªëng k√™ h·ªá th·ªëng
GET /stats
```

## üß† Modern Algorithm Details

### Skills Matching (40%) - Hybrid Approach
- **Exact Matching (60%)**: Traditional string matching v·ªõi skill aliases
- **Semantic Matching (40%)**: Embeddings + cosine similarity
- **Combined Score**: Weighted combination c·ªßa c·∫£ hai approaches
- **Skill Groups**: Gom nh√≥m skills li√™n quan (React ecosystem, Python stack, etc.)

### Experience Matching (30%) - Dual Analysis
- **Years Analysis (70%)**: Extract v√† so s√°nh s·ªë nƒÉm kinh nghi·ªám
- **Semantic Analysis (30%)**: Embeddings c·ªßa work experience vs job requirements
- **Graduated Scoring**: 
  - ‚â• requirement: 100%
  - ‚â• 80% requirement: 90%
  - ‚â• 60% requirement: 70%
  - < 60% requirement: 30-50%

### Semantic Similarity (20%) - Pure Embeddings
- **Sentence Transformers**: all-MiniLM-L6-v2 model
- **CV Embeddings**: Summary, objective, experience descriptions
- **Job Embeddings**: Title, description, requirements
- **Cosine Similarity**: Normalized similarity score [0,1]
- **Embedding Cache**: T·ªëi ∆∞u performance v·ªõi caching

### Education & Location (10%) - Rule-based
- **Education Hierarchy**: PhD > Master > Bachelor > College > Diploma
- **Location Matching**: Exact, major cities, remote work detection
- **Fallback Logic**: Robust handling cho missing data

## üî¨ Technical Implementation

### Embedding Pipeline
```python
# 1. Text Preprocessing
cv_text = extract_relevant_sections(cv_data)
job_text = create_comprehensive_job_text(job_data)

# 2. Embedding Generation
cv_embedding = sentence_model.encode(cv_text, normalize_embeddings=True)
job_embedding = sentence_model.encode(job_text, normalize_embeddings=True)

# 3. Similarity Calculation
similarity = cosine_similarity(cv_embedding.reshape(1, -1), 
                              job_embedding.reshape(1, -1))[0][0]

# 4. Normalization: [-1,1] ‚Üí [0,1]
normalized_score = (similarity + 1) / 2
```

### Performance Optimizations
- **Embedding Caching**: Cache computed embeddings ƒë·ªÉ tr√°nh re-computation
- **Batch Processing**: Process multiple jobs simultaneously
- **Pre-computed CV Embeddings**: Compute CV embeddings m·ªôt l·∫ßn, reuse cho t·∫•t c·∫£ jobs
- **Fallback Mechanism**: TF-IDF fallback n·∫øu Sentence Transformer fails

## üîç Example Usage

### 1. Upload CV v√† Nh·∫≠n Recommendations
```python
import requests

# Upload CV file
files = {'file': open('cv.pdf', 'rb')}
params = {'top_k': 5, 'min_score': 0.4}

response = requests.post(
    'http://localhost:8000/cv/upload',
    files=files,
    params=params
)

result = response.json()
print(f"T√¨m th·∫•y {len(result['recommendations'])} c√¥ng vi·ªác ph√π h·ª£p")
```

### 2. Upload Job Description
```python
job_data = {
        "job_title": "Python Developer",
    "company": "TechCorp",
    "location": "H√† N·ªôi",
    "job_type": "Full-time",
    "description": "Ph√°t tri·ªÉn ·ª©ng d·ª•ng web v·ªõi Python",
    "required_skills": ["Python", "Django", "PostgreSQL"],
    "experience_required": "2-3 nƒÉm kinh nghi·ªám"
}

response = requests.post(
    'http://localhost:8000/jobs/upload',
    json={"job_data": job_data}
)
```

### 3. Generate Recommendations v·ªõi Filters
```python
request_data = {
    "cv_data": cv_data,  # CV data object
    "location_filter": "H√† N·ªôi",
    "job_type_filter": "Full-time",
    "top_k": 10,
    "min_score": 0.3
}

response = requests.post(
    'http://localhost:8000/recommendations/generate',
    json=request_data
)
```

## üîß Configuration

### config.py Settings
```python
# Model settings
LLM_MODEL = "gemini-2.0-flash"
SENTENCE_TRANSFORMER_MODEL = "all-MiniLM-L6-v2"

# Matching weights
MATCHING_WEIGHTS = {
    'skills_match': 0.40,
    'experience_match': 0.30,
    'semantic_similarity': 0.20,
    'education_match': 0.05,
    'location_match': 0.05
}

# File settings
MAX_FILE_SIZE_MB = 10
SUPPORTED_FILE_TYPES = ['.pdf', '.docx', '.doc', '.jpg', '.jpeg', '.png']
```

## üß™ Testing

### 1. Add Sample Jobs
```bash
curl -X POST http://localhost:8000/test/add-sample-jobs
```

### 2. Test CV Upload
```bash
curl -X POST \
  -F "file=@sample_cv.pdf" \
  -F "top_k=5" \
  http://localhost:8000/cv/upload
```

### 3. Health Check
```bash
curl http://localhost:8000/health
```

## üîÑ Integration v·ªõi TopCV Backend

### Database Integration
Thay th·∫ø `job_database` in-memory b·∫±ng PostgreSQL:

```python
# Trong production, thay th·∫ø b·∫±ng:
from sqlalchemy import create_engine
from core.database import JobRepository

job_repository = JobRepository(database_url)
jobs = job_repository.get_active_jobs()
```

### API Integration
T√≠ch h·ª£p v√†o TopCV system:

```java
// Java backend call Python service
@Service
public class RecommendationService {
    public List<JobRecommendation> getRecommendations(Long userId) {
        // Call Python API
        String url = "http://recommendation-service:8000/recommendations/generate";
        // Process response
    }
}
```

## üöß Future Enhancements

1. **Vector Search**: S·ª≠ d·ª•ng embeddings cho semantic search
2. **ML Model**: Train custom model cho Vietnamese job market
3. **Real-time Processing**: Kafka streaming cho real-time recommendations
4. **A/B Testing**: Framework ƒë·ªÉ test c√°c algorithms kh√°c nhau
5. **Explainable AI**: Chi ti·∫øt l√Ω do recommend t·ª´ng job

## üìä Performance

- **CV Processing**: ~2-5 seconds/file
- **Recommendations**: ~100-500ms cho 1000 jobs
- **Throughput**: ~100 requests/second
- **Memory Usage**: ~500MB baseline

## ü§ù Contributing

1. Fork repository
2. Create feature branch
3. Implement changes v·ªõi tests
4. Submit pull request

## üìù License

Copyright TopCV Vietnam. All rights reserved. 